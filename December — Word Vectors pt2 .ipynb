{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "## As used in [\"Word embeddings quantify 100 years of gender and ethnic stereotypes\"](https://doi.org/10.1073/pnas.1720347115)\n",
    "\n",
    "The article by Garg et al. investigates and validates the use of machine-learned word embeddings to study biases in language:\n",
    "\n",
    "```\n",
    "\"In word-embedding models, each word in a given language is assigned to a high-dimensional vector such that the geometry of the vectors captures semantic relations between the words — e.g., vectors being closer together has been shown to correspond to more similar words.\"\n",
    "```\n",
    "\n",
    "Using pre-trained models of large text corpora, the authors evaluate vectors of words relating to gender and ethnicity against \"neutral\" word categories to measure bias.\n",
    "\n",
    "### Load model(s) and look at vectors\n",
    "\n",
    "```\n",
    "\"For contemporary snapshot analysis, we use the standard Google News word2vec vectors trained on the Google News dataset.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of each word's vector (for this model):\", len(model[\"cat\"]))\n",
    "print(\"Sample vector for 'cat':\")\n",
    "print(model[\"cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can you do with word vectors?\n",
    "\n",
    "The [documentation](https://radimrehurek.com/gensim/models/keyedvectors.html) (API) lists out all the associated functions and how they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.similar_by_word(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"democracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"man\" is to \"king\" as \"woman\" is to _______\n",
    "\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"paltry\" is to \"significance\" as \"banal\" is to _______\n",
    "\n",
    "model.most_similar(positive=['banal', 'significance'], negative=['paltry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"clumsy\" is to \"botch\" as \"lazy\" is to ________\n",
    "\n",
    "model.most_similar(positive=['botch', 'lazy'], negative=['clumsy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.similarity('woman', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"freedom\", topn=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Average Embeddings\n",
    "\n",
    "```\n",
    "\"We first compute the average embedding distance between words that represent women—e.g., she, female—and words for occupations—e.g., teacher, lawyer.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean of vectors among all words of each category.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "woman_words = [\"she\", \"daughter\", \"hers\", \"her\", \"mother\", \"woman\", \"girl\", \"herself\", \"female\", \"sister\", \"daughters\", \"mothers\", \"women\",\n",
    "\"girls\", \"femen\", \"sisters\", \"aunt\", \"aunts\", \"niece\", \"nieces\"]\n",
    "\n",
    "man_words = [\"he\", \"son\", \"his\", \"him\", \"father\", \"man\", \"boy\", \"himself\", \"male\", \"brother\", \"sons\", \"fathers\", \"men\", \"boys\", \"males\", \"brothers\", \"uncle\",\n",
    "\"uncles\", \"nephew\", \"nephews\"]\n",
    "\n",
    "occupations = [\"janitor\", \"statistician\", \"midwife\", \"bailiff\", \"auctioneer\", \"photographer\", \"geologist\", \"shoemaker\", \"athlete\", \"cashier\",\n",
    "\"dancer\", \"housekeeper\", \"accountant\", \"physicist\", \"gardener\", \"dentist\", \"weaver\", \"blacksmith\", \"psychologist\", \"supervisor\",\n",
    "\"mathematician\", \"surveyor\", \"tailor\", \"designer\", \"economist\", \"mechanic\", \"laborer\", \"postmaster\", \"broker\", \"chemist\", \"librarian\", \"attendant\", \"clerical\", \"musician\", \"porter\", \"scientist\", \"carpenter\", \"sailor\", \"instructor\", \"sheriff\", \"pilot\", \"inspector\", \"mason\",\n",
    "\"baker\", \"administrator\", \"architect\", \"collector\", \"operator\", \"surgeon\", \"driver\", \"painter\", \"conductor\", \"nurse\", \"cook\", \"engineer\",\n",
    "\"retired\", \"sales\", \"lawyer\", \"clergy\", \"physician\", \"farmer\", \"clerk\", \"manager\", \"guard\", \"artist\", \"smith\", \"official\", \"police\", \"doctor\",\n",
    "\"professor\", \"student\", \"judge\", \"teacher\", \"author\", \"secretary\", \"soldier\"]\n",
    "\n",
    "prof_occupations = [\"statistician\", \"auctioneer\", \"photographer\", \"geologist\", \"accountant\", \"physicist\", \"dentist\", \"psychologist\", \"supervisor\", \"mathematician\", \"designer\", \"economist\", \"postmaster\", \"broker\", \"chemist\", \"librarian\", \"scientist\", \"instructor\",\n",
    "\"pilot\", \"administrator\", \"architect\", \"surgeon\", \"nurse\", \"engineer\", \"lawyer\", \"physician\", \"manager\", \"official\", \"doctor\", \"professor\",\n",
    "\"student\", \"judge\", \"teacher\", \"author\"]\n",
    "\n",
    "personality_traits = ['disorganized', 'devious', 'impressionable', 'circumspect', 'impassive', 'aimless', 'effeminate', 'unfathomable', 'fickle', 'unprincipled', 'inoffensive', 'reactive', 'providential', 'resentful', 'bizarre', 'impractical', 'sarcastic', 'misguided', 'imitative', 'pedantic', 'venomous', 'erratic', 'insecure', 'resourceful', 'neurotic', 'forgiving', 'profligate', 'whimsical', 'assertive', 'incorruptible', 'individualistic', 'faithless', 'disconcerting', 'barbaric', 'hypnotic', 'vindictive', 'observant', 'dissolute', 'frightening', 'complacent', 'boisterous', 'pretentious', 'disobedient', 'tasteless', 'sedentary', 'sophisticated', 'regimental', 'mellow', 'deceitful', 'impulsive', 'playful', 'sociable', 'methodical', 'willful', 'idealistic', 'boyish', 'callous', 'pompous', 'unchanging', 'crafty', 'punctual', 'compassionate', 'intolerant', 'challenging', 'scornful', 'possessive', 'conceited', 'imprudent', 'dutiful', 'lovable', 'disloyal', 'dreamy', 'appreciative', 'forgetful', 'unrestrained', 'forceful', 'submissive', 'predatory', 'fanatical', 'illogical', 'tidy', 'aspiring', 'studious', 'adaptable', 'conciliatory', 'artful', 'thoughtless', 'deceptive', 'frugal', 'reflective', 'insulting', 'unreliable', 'stoic', 'hysterical', 'rustic', 'inhibited', 'outspoken', 'unhealthy', 'ascetic', 'skeptical', 'painstaking', 'contemplative', 'leisurely', 'sly', 'mannered', 'outrageous', 'lyrical', 'placid', 'cynical', 'irresponsible', 'vulnerable', 'arrogant', 'persuasive', 'perverse', 'steadfast', 'crisp', 'envious', 'naive', 'greedy', 'presumptuous', 'obnoxious', 'irritable', 'dishonest', 'discreet', 'sporting', 'hateful', 'ungrateful', 'frivolous', 'reactionary', 'skillful', 'cowardly', 'sordid', 'adventurous', 'dogmatic', 'intuitive', 'bland', 'indulgent', 'discontented', 'dominating', 'articulate', 'fanciful', 'discouraging', 'treacherous', 'repressed', 'moody', 'sensual', 'unfriendly', 'optimistic', 'clumsy', 'contemptible', 'focused', 'haughty', 'morbid', 'disorderly', 'considerate', 'humorous', 'preoccupied', 'airy', 'impersonal', 'cultured', 'trusting', 'respectful', 'scrupulous', 'scholarly', 'superstitious', 'tolerant', 'realistic', 'malicious', 'irrational', 'sane', 'colorless', 'masculine', 'witty', 'inert', 'prejudiced', 'fraudulent', 'blunt', 'childish', 'brittle', 'disciplined', 'responsive', 'courageous', 'bewildered', 'courteous', 'stubborn', 'aloof', 'sentimental', 'athletic', 'extravagant', 'brutal', 'manly', 'cooperative', 'unstable', 'youthful', 'timid', 'amiable', 'retiring', 'fiery', 'confidential', 'relaxed', 'imaginative', 'mystical', 'shrewd', 'conscientious', 'monstrous', 'grim', 'questioning', 'lazy', 'dynamic', 'gloomy', 'troublesome', 'abrupt', 'eloquent', 'dignified', 'hearty', 'gallant', 'benevolent', 'maternal', 'paternal', 'patriotic', 'aggressive', 'competitive', 'elegant', 'flexible', 'gracious', 'energetic', 'tough', 'contradictory', 'shy', 'careless', 'cautious', 'polished', 'sage', 'tense', 'caring', 'suspicious', 'sober', 'neat', 'transparent', 'disturbing', 'passionate', 'obedient', 'crazy', 'restrained', 'fearful', 'daring', 'prudent', 'demanding', 'impatient', 'cerebral', 'calculating', 'amusing', 'honorable', 'casual', 'sharing', 'selfish', 'ruined', 'spontaneous', 'admirable', 'conventional', 'cheerful', 'solitary', 'upright', 'stiff', 'enthusiastic', 'petty', 'dirty', 'subjective', 'heroic', 'stupid', 'modest', 'impressive', 'orderly', 'ambitious', 'protective', 'silly', 'alert', 'destructive', 'exciting', 'crude', 'ridiculous', 'subtle', 'mature', 'creative', 'coarse', 'passive', 'oppressed', 'accessible', 'charming', 'clever', 'decent', 'miserable', 'superficial', 'shallow', 'stern', 'winning', 'balanced', 'emotional', 'rigid', 'invisible', 'desperate', 'cruel', 'romantic', 'agreeable', 'hurried', 'sympathetic', 'solemn', 'systematic', 'vague', 'peaceful', 'humble', 'dull', 'expedient', 'loyal', 'decisive', 'arbitrary', 'earnest', 'confident', 'conservative', 'foolish', 'moderate', 'helpful', 'delicate', 'gentle', 'dedicated', 'hostile', 'generous', 'reliable', 'dramatic', 'precise', 'calm', 'healthy', 'attractive', 'artificial', 'progressive', 'odd', 'confused', 'rational', 'brilliant', 'intense', 'genuine', 'mistaken', 'driving', 'stable', 'objective', 'sensitive', 'neutral', 'strict', 'angry', 'profound', 'smooth', 'ignorant', 'thorough', 'logical', 'intelligent', 'extraordinary', 'experimental', 'steady', 'formal', 'faithful', 'curious', 'reserved', 'honest', 'busy', 'educated', 'liberal', 'friendly', 'efficient', 'sweet', 'surprising', 'mechanical', 'clean', 'critical', 'criminal', 'soft', 'proud', 'quiet', 'weak', 'anxious', 'solid', 'complex', 'grand', 'warm', 'slow', 'false', 'extreme', 'narrow', 'dependent', 'wise', 'organized', 'pure', 'directed', 'dry', 'obvious', 'popular', 'capable', 'secure', 'active', 'independent', 'ordinary', 'fixed', 'practical', 'serious', 'fair', 'understanding', 'constant', 'cold', 'responsible', 'deep', 'religious', 'private', 'simple', 'physical', 'original', 'working', 'strong', 'modern', 'determined', 'open', 'political', 'difficult', 'knowledge', 'kind']\n",
    "\n",
    "average_woman_words = np.mean(np.array([model[word] for word in woman_words if word in model]), axis = 0)\n",
    "average_man_words = np.mean(np.array([model[word] for word in man_words if word in model]), axis = 0)\n",
    "average_occupations = np.mean(np.array([model[word] for word in occupations if word in model]), axis = 0)\n",
    "average_prof_occupations = np.mean(np.array([model[word] for word in prof_occupations if word in model]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(average_woman_words))\n",
    "print(len(average_man_words))\n",
    "print(len(average_occupations))\n",
    "print(len(average_prof_occupations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances between occations and 'man' and 'woman' words.\n",
    "def cossim(v1, v2, signed = True):\n",
    "    c = np.dot(v1, v2)/np.linalg.norm(v1)/np.linalg.norm(v2)\n",
    "    if not signed:\n",
    "        return abs(c)\n",
    "    return c\n",
    "\n",
    "def calc_distance_between_vectors(vec1, vec2, distype = ''):\n",
    "    if distype == 'norm':\n",
    "        return np.linalg.norm(np.subtract(vec1, vec2))\n",
    "    else:\n",
    "        return cossim(vec1, vec2)\n",
    "\n",
    "occupations_to_woman = calc_distance_between_vectors(average_occupations, average_woman_words)\n",
    "occupations_to_man = calc_distance_between_vectors(average_occupations, average_man_words)\n",
    "print(\"Occupation distances (women, men):\", occupations_to_woman, occupations_to_man)\n",
    "\n",
    "prof_occupations_to_woman = calc_distance_between_vectors(average_prof_occupations, average_woman_words)\n",
    "prof_occupations_to_man = calc_distance_between_vectors(average_prof_occupations, average_man_words)\n",
    "print(\"Occupation distances (women, men):\", prof_occupations_to_woman, prof_occupations_to_man)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\"A natural metric for the embedding bias is the average distance for women minus the average distance for men. If this value is negative, then the embedding more closely associates the occupations with men.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_bias = occupations_to_woman - occupations_to_man\n",
    "print(embedding_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "output = []\n",
    "\n",
    "for occupation in occupations:\n",
    "    man = calc_distance_between_vectors(model[occupation], average_man_words)\n",
    "    woman = calc_distance_between_vectors(model[occupation], average_woman_words)\n",
    "    output.append([occupation, woman - man])  \n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "display(pd.DataFrame(output, columns=[\"Occupation\", \"Woman Bias\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "\n",
    "for occupation in prof_occupations:\n",
    "    man = calc_distance_between_vectors(model[occupation], average_man_words)\n",
    "    woman = calc_distance_between_vectors(model[occupation], average_woman_words)\n",
    "    output.append([occupation, woman - man])  \n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "display(pd.DataFrame(output, columns=[\"Occupation\", \"Woman Bias\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "\n",
    "for t in personality_traits:\n",
    "    man = calc_distance_between_vectors(model[t], average_man_words)\n",
    "    woman = calc_distance_between_vectors(model[t], average_woman_words)\n",
    "    output.append([t, woman - man])  \n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "display(pd.DataFrame(output, columns=[\"Trait\", \"Woman Bias\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Data\n",
    "\n",
    "Loading Sample COHA corpora, divided by decade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "with open(\"1950-w.npy\", \"rb\") as f:\n",
    "    vectors = np.lib.format.read_array(f)\n",
    "\n",
    "with open(\"1950-vocab.pkl\", \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "model50s = KeyedVectors(vectors.shape[1])\n",
    "model50s.add_vectors(vocab, vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"2000-w.npy\", \"rb\") as f:\n",
    "    vectors = np.lib.format.read_array(f)\n",
    "\n",
    "with open(\"2000-vocab.pkl\", \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "model00s = KeyedVectors(vectors.shape[1])\n",
    "model00s.add_vectors(vocab, vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woman_words = [\"she\", \"daughter\", \"hers\", \"her\", \"mother\", \"woman\", \"girl\", \"herself\", \"female\", \"sister\", \"daughters\", \"mothers\", \"women\",\n",
    "\"girls\", \"femen\", \"sisters\", \"aunt\", \"aunts\", \"niece\", \"nieces\"]\n",
    "\n",
    "man_words = [\"he\", \"son\", \"his\", \"him\", \"father\", \"man\", \"boy\", \"himself\", \"male\", \"brother\", \"sons\", \"fathers\", \"men\", \"boys\", \"males\", \"brothers\", \"uncle\",\n",
    "\"uncles\", \"nephew\", \"nephews\"]\n",
    "\n",
    "occupations = [\"janitor\", \"statistician\", \"midwife\", \"bailiff\", \"auctioneer\", \"photographer\", \"geologist\", \"shoemaker\", \"athlete\", \"cashier\",\n",
    "\"dancer\", \"housekeeper\", \"accountant\", \"physicist\", \"gardener\", \"dentist\", \"weaver\", \"blacksmith\", \"psychologist\", \"supervisor\",\n",
    "\"mathematician\", \"surveyor\", \"tailor\", \"designer\", \"economist\", \"mechanic\", \"laborer\", \"postmaster\", \"broker\", \"chemist\", \"librarian\", \"attendant\", \"clerical\", \"musician\", \"porter\", \"scientist\", \"carpenter\", \"sailor\", \"instructor\", \"sheriff\", \"pilot\", \"inspector\", \"mason\",\n",
    "\"baker\", \"administrator\", \"architect\", \"collector\", \"operator\", \"surgeon\", \"driver\", \"painter\", \"conductor\", \"nurse\", \"cook\", \"engineer\",\n",
    "\"retired\", \"sales\", \"lawyer\", \"clergy\", \"physician\", \"farmer\", \"clerk\", \"manager\", \"guard\", \"artist\", \"smith\", \"official\", \"police\", \"doctor\",\n",
    "\"professor\", \"student\", \"judge\", \"teacher\", \"author\", \"secretary\", \"soldier\"]\n",
    "\n",
    "prof_occupations = [\"statistician\", \"auctioneer\", \"photographer\", \"geologist\", \"accountant\", \"physicist\", \"dentist\", \"psychologist\", \"supervisor\", \"mathematician\", \"designer\", \"economist\", \"postmaster\", \"broker\", \"chemist\", \"librarian\", \"scientist\", \"instructor\",\n",
    "\"pilot\", \"administrator\", \"architect\", \"surgeon\", \"nurse\", \"engineer\", \"lawyer\", \"physician\", \"manager\", \"official\", \"doctor\", \"professor\",\n",
    "\"student\", \"judge\", \"teacher\", \"author\"]\n",
    "\n",
    "personality_traits = ['disorganized', 'devious', 'impressionable', 'circumspect', 'impassive', 'aimless', 'effeminate', 'unfathomable', 'fickle', 'unprincipled', 'inoffensive', 'reactive', 'providential', 'resentful', 'bizarre', 'impractical', 'sarcastic', 'misguided', 'imitative', 'pedantic', 'venomous', 'erratic', 'insecure', 'resourceful', 'neurotic', 'forgiving', 'profligate', 'whimsical', 'assertive', 'incorruptible', 'individualistic', 'faithless', 'disconcerting', 'barbaric', 'hypnotic', 'vindictive', 'observant', 'dissolute', 'frightening', 'complacent', 'boisterous', 'pretentious', 'disobedient', 'tasteless', 'sedentary', 'sophisticated', 'regimental', 'mellow', 'deceitful', 'impulsive', 'playful', 'sociable', 'methodical', 'willful', 'idealistic', 'boyish', 'callous', 'pompous', 'unchanging', 'crafty', 'punctual', 'compassionate', 'intolerant', 'challenging', 'scornful', 'possessive', 'conceited', 'imprudent', 'dutiful', 'lovable', 'disloyal', 'dreamy', 'appreciative', 'forgetful', 'unrestrained', 'forceful', 'submissive', 'predatory', 'fanatical', 'illogical', 'tidy', 'aspiring', 'studious', 'adaptable', 'conciliatory', 'artful', 'thoughtless', 'deceptive', 'frugal', 'reflective', 'insulting', 'unreliable', 'stoic', 'hysterical', 'rustic', 'inhibited', 'outspoken', 'unhealthy', 'ascetic', 'skeptical', 'painstaking', 'contemplative', 'leisurely', 'sly', 'mannered', 'outrageous', 'lyrical', 'placid', 'cynical', 'irresponsible', 'vulnerable', 'arrogant', 'persuasive', 'perverse', 'steadfast', 'crisp', 'envious', 'naive', 'greedy', 'presumptuous', 'obnoxious', 'irritable', 'dishonest', 'discreet', 'sporting', 'hateful', 'ungrateful', 'frivolous', 'reactionary', 'skillful', 'cowardly', 'sordid', 'adventurous', 'dogmatic', 'intuitive', 'bland', 'indulgent', 'discontented', 'dominating', 'articulate', 'fanciful', 'discouraging', 'treacherous', 'repressed', 'moody', 'sensual', 'unfriendly', 'optimistic', 'clumsy', 'contemptible', 'focused', 'haughty', 'morbid', 'disorderly', 'considerate', 'humorous', 'preoccupied', 'airy', 'impersonal', 'cultured', 'trusting', 'respectful', 'scrupulous', 'scholarly', 'superstitious', 'tolerant', 'realistic', 'malicious', 'irrational', 'sane', 'colorless', 'masculine', 'witty', 'inert', 'prejudiced', 'fraudulent', 'blunt', 'childish', 'brittle', 'disciplined', 'responsive', 'courageous', 'bewildered', 'courteous', 'stubborn', 'aloof', 'sentimental', 'athletic', 'extravagant', 'brutal', 'manly', 'cooperative', 'unstable', 'youthful', 'timid', 'amiable', 'retiring', 'fiery', 'confidential', 'relaxed', 'imaginative', 'mystical', 'shrewd', 'conscientious', 'monstrous', 'grim', 'questioning', 'lazy', 'dynamic', 'gloomy', 'troublesome', 'abrupt', 'eloquent', 'dignified', 'hearty', 'gallant', 'benevolent', 'maternal', 'paternal', 'patriotic', 'aggressive', 'competitive', 'elegant', 'flexible', 'gracious', 'energetic', 'tough', 'contradictory', 'shy', 'careless', 'cautious', 'polished', 'sage', 'tense', 'caring', 'suspicious', 'sober', 'neat', 'transparent', 'disturbing', 'passionate', 'obedient', 'crazy', 'restrained', 'fearful', 'daring', 'prudent', 'demanding', 'impatient', 'cerebral', 'calculating', 'amusing', 'honorable', 'casual', 'sharing', 'selfish', 'ruined', 'spontaneous', 'admirable', 'conventional', 'cheerful', 'solitary', 'upright', 'stiff', 'enthusiastic', 'petty', 'dirty', 'subjective', 'heroic', 'stupid', 'modest', 'impressive', 'orderly', 'ambitious', 'protective', 'silly', 'alert', 'destructive', 'exciting', 'crude', 'ridiculous', 'subtle', 'mature', 'creative', 'coarse', 'passive', 'oppressed', 'accessible', 'charming', 'clever', 'decent', 'miserable', 'superficial', 'shallow', 'stern', 'winning', 'balanced', 'emotional', 'rigid', 'invisible', 'desperate', 'cruel', 'romantic', 'agreeable', 'hurried', 'sympathetic', 'solemn', 'systematic', 'vague', 'peaceful', 'humble', 'dull', 'expedient', 'loyal', 'decisive', 'arbitrary', 'earnest', 'confident', 'conservative', 'foolish', 'moderate', 'helpful', 'delicate', 'gentle', 'dedicated', 'hostile', 'generous', 'reliable', 'dramatic', 'precise', 'calm', 'healthy', 'attractive', 'artificial', 'progressive', 'odd', 'confused', 'rational', 'brilliant', 'intense', 'genuine', 'mistaken', 'driving', 'stable', 'objective', 'sensitive', 'neutral', 'strict', 'angry', 'profound', 'smooth', 'ignorant', 'thorough', 'logical', 'intelligent', 'extraordinary', 'experimental', 'steady', 'formal', 'faithful', 'curious', 'reserved', 'honest', 'busy', 'educated', 'liberal', 'friendly', 'efficient', 'sweet', 'surprising', 'mechanical', 'clean', 'critical', 'criminal', 'soft', 'proud', 'quiet', 'weak', 'anxious', 'solid', 'complex', 'grand', 'warm', 'slow', 'false', 'extreme', 'narrow', 'dependent', 'wise', 'organized', 'pure', 'directed', 'dry', 'obvious', 'popular', 'capable', 'secure', 'active', 'independent', 'ordinary', 'fixed', 'practical', 'serious', 'fair', 'understanding', 'constant', 'cold', 'responsible', 'deep', 'religious', 'private', 'simple', 'physical', 'original', 'working', 'strong', 'modern', 'determined', 'open', 'political', 'difficult', 'knowledge', 'kind']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate distances between occations and 'man' and 'woman' words.\n",
    "def cossim(v1, v2, signed = True):\n",
    "    c = np.dot(v1, v2)/np.linalg.norm(v1)/np.linalg.norm(v2)\n",
    "    if not signed:\n",
    "        return abs(c)\n",
    "    return c\n",
    "\n",
    "def calc_distance_between_vectors(vec1, vec2, distype = ''):\n",
    "    if distype == 'norm':\n",
    "        return np.linalg.norm(np.subtract(vec1, vec2))\n",
    "    else:\n",
    "        return cossim(vec1, vec2)\n",
    "\n",
    "models = {}\n",
    "output = []\n",
    "\n",
    "for decade, model in [(\"1950s\", model50s), (\"2000s\", model00s)]:\n",
    "    \n",
    "    average_woman_words = np.mean(np.array([model[word] for word in woman_words if word in model]), axis = 0)\n",
    "    average_man_words = np.mean(np.array([model[word] for word in man_words if word in model]), axis = 0)\n",
    "    average_occupations = np.mean(np.array([model[word] for word in occupations if word in model]), axis = 0)\n",
    "    models[decade] = [average_occupations, average_woman_words, average_man_words]\n",
    "\n",
    "available_occupations = [o for o in occupations if np.any(model50s[o]) and np.any(model00s[o])]\n",
    "\n",
    "for occupation in available_occupations:\n",
    "    row = [occupation]\n",
    "    for decade, model in [(\"1950s\", model50s), (\"2000s\", model00s)]:\n",
    "        man = calc_distance_between_vectors(model[occupation], models[decade][2]) # the average vectors for men are found at index 2.\n",
    "        woman = calc_distance_between_vectors(model[occupation], models[decade][1])\n",
    "        row.append(woman - man)  \n",
    "    output.append(row)\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "display(pd.DataFrame(output, columns=[\"Occupation\", \"Woman Bias 1950s\", \"Woman Bias 2000s\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances between occations and 'man' and 'woman' words.\n",
    "def cossim(v1, v2, signed = True):\n",
    "    c = np.dot(v1, v2)/np.linalg.norm(v1)/np.linalg.norm(v2)\n",
    "    if not signed:\n",
    "        return abs(c)\n",
    "    return c\n",
    "\n",
    "def calc_distance_between_vectors(vec1, vec2, distype = ''):\n",
    "    if distype == 'norm':\n",
    "        return np.linalg.norm(np.subtract(vec1, vec2))\n",
    "    else:\n",
    "        return cossim(vec1, vec2)\n",
    "\n",
    "models = {}\n",
    "output = []\n",
    "\n",
    "for decade, model in [(\"1950s\", model50s), (\"2000s\", model00s)]:\n",
    "    \n",
    "    average_woman_words = np.mean(np.array([model[word] for word in woman_words if word in model]), axis = 0)\n",
    "    average_man_words = np.mean(np.array([model[word] for word in man_words if word in model]), axis = 0)\n",
    "    models[decade] = [average_woman_words, average_man_words]\n",
    "\n",
    "available_traits = [p for p in personality_traits if np.any(model50s[p]) and np.any(model00s[p])]\n",
    "\n",
    "for trait in available_traits:\n",
    "    row = [trait]\n",
    "    for decade, model in [(\"1950s\", model50s), (\"2000s\", model00s)]:\n",
    "        man = calc_distance_between_vectors(model[trait], models[decade][1]) # the average vectors for men are found at index 2.\n",
    "        woman = calc_distance_between_vectors(model[trait], models[decade][0])\n",
    "        row.append(woman - man)  \n",
    "    output.append(row)\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "display(pd.DataFrame(output, columns=[\"Trait\", \"Woman Bias 1950s\", \"Woman Bias 2000s\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test some words using either or both of the models! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
