{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cd2278f-6b7f-458d-b6f5-f2cfb316520f",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "## As used in \"Word embeddings quantify 100 years of gender and ethnic stereotypes\"\n",
    "\n",
    "The article by Garg et al. investigates and validates the use of machine-learned word embeddings to study biases in language:\n",
    "\n",
    "```\n",
    "\"In word-embedding models, each word in a given language is assigned to a high-dimensional vector such that the geometry of the vectors captures semantic relations between the words — e.g., vectors being closer together has been shown to correspond to more similar words.\"\n",
    "```\n",
    "\n",
    "Using pre-trained models of large text corpora, the authors evaluate vectors of words relating to gender and ethnicity against \"neutral\" word categories to measure bias.\n",
    "\n",
    "### Load model(s) and look at vectors\n",
    "\n",
    "```\n",
    "\"For contemporary snapshot analysis, we use the standard Google News word2vec vectors trained on the Google News dataset.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818b7c0d-6062-4cd8-9680-6997f1361a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e830c9c-7c7f-414b-b7c5-66b18b0fe008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of each word's vector (for this model): 300\n",
      "Sample vector for 'cat':\n",
      "[ 0.0123291   0.20410156 -0.28515625  0.21679688  0.11816406  0.08300781\n",
      "  0.04980469 -0.00952148  0.22070312 -0.12597656  0.08056641 -0.5859375\n",
      " -0.00445557 -0.296875   -0.01312256 -0.08349609  0.05053711  0.15136719\n",
      " -0.44921875 -0.0135498   0.21484375 -0.14746094  0.22460938 -0.125\n",
      " -0.09716797  0.24902344 -0.2890625   0.36523438  0.41210938 -0.0859375\n",
      " -0.07861328 -0.19726562 -0.09082031 -0.14160156 -0.10253906  0.13085938\n",
      " -0.00346375  0.07226562  0.04418945  0.34570312  0.07470703 -0.11230469\n",
      "  0.06738281  0.11230469  0.01977539 -0.12353516  0.20996094 -0.07226562\n",
      " -0.02783203  0.05541992 -0.33398438  0.08544922  0.34375     0.13964844\n",
      "  0.04931641 -0.13476562  0.16308594 -0.37304688  0.39648438  0.10693359\n",
      "  0.22167969  0.21289062 -0.08984375  0.20703125  0.08935547 -0.08251953\n",
      "  0.05957031  0.10205078 -0.19238281 -0.09082031  0.4921875   0.03955078\n",
      " -0.07080078 -0.0019989  -0.23046875  0.25585938  0.08984375 -0.10644531\n",
      "  0.00105286 -0.05883789  0.05102539 -0.0291748   0.19335938 -0.14160156\n",
      " -0.33398438  0.08154297 -0.27539062  0.10058594 -0.10449219 -0.12353516\n",
      " -0.140625    0.03491211 -0.11767578 -0.1796875  -0.21484375 -0.23828125\n",
      "  0.08447266 -0.07519531 -0.25976562 -0.21289062 -0.22363281 -0.09716797\n",
      "  0.11572266  0.15429688  0.07373047 -0.27539062  0.14257812 -0.0201416\n",
      "  0.10009766 -0.19042969 -0.09375     0.14160156  0.17089844  0.3125\n",
      " -0.16699219 -0.08691406 -0.05004883 -0.24902344 -0.20800781 -0.09423828\n",
      " -0.12255859 -0.09472656 -0.390625   -0.06640625 -0.31640625  0.10986328\n",
      " -0.00156403  0.04345703  0.15625    -0.18945312 -0.03491211  0.03393555\n",
      " -0.14453125  0.01611328 -0.14160156 -0.02392578  0.01501465  0.07568359\n",
      "  0.10742188  0.12695312  0.10693359 -0.01184082 -0.24023438  0.0291748\n",
      "  0.16210938  0.19921875 -0.28125     0.16699219 -0.11621094 -0.25585938\n",
      "  0.38671875 -0.06640625 -0.4609375  -0.06176758 -0.14453125 -0.11621094\n",
      "  0.05688477  0.03588867 -0.10693359  0.18847656 -0.16699219 -0.01794434\n",
      "  0.10986328 -0.12353516 -0.16308594 -0.14453125  0.12890625  0.11523438\n",
      "  0.13671875  0.05688477 -0.08105469 -0.06152344 -0.06689453  0.27929688\n",
      " -0.19628906  0.07226562  0.12304688 -0.20996094 -0.22070312  0.21386719\n",
      " -0.1484375  -0.05932617  0.05224609  0.06445312 -0.02636719  0.13183594\n",
      "  0.19433594  0.27148438  0.18652344  0.140625    0.06542969 -0.14453125\n",
      "  0.05029297  0.08837891  0.12255859  0.26757812  0.0534668  -0.32226562\n",
      " -0.20703125  0.18164062  0.04418945 -0.22167969 -0.13769531 -0.04174805\n",
      " -0.00286865  0.04077148  0.07275391 -0.08300781  0.08398438 -0.3359375\n",
      " -0.40039062  0.01757812 -0.18652344 -0.0480957  -0.19140625  0.10107422\n",
      "  0.09277344 -0.30664062 -0.19921875 -0.0168457   0.12207031  0.14648438\n",
      " -0.12890625 -0.23535156 -0.05371094 -0.06640625  0.06884766 -0.03637695\n",
      "  0.2109375  -0.06005859  0.19335938  0.05151367 -0.05322266  0.02893066\n",
      " -0.27539062  0.08447266  0.328125    0.01818848  0.01495361  0.04711914\n",
      "  0.37695312 -0.21875    -0.03393555  0.01116943  0.36914062  0.02160645\n",
      "  0.03466797  0.07275391  0.16015625 -0.16503906 -0.296875    0.15039062\n",
      " -0.29101562  0.13964844  0.00448608  0.171875   -0.21972656  0.09326172\n",
      " -0.19042969  0.01599121 -0.09228516  0.15722656 -0.14160156 -0.0534668\n",
      "  0.03613281  0.23632812 -0.15136719 -0.00689697 -0.27148438 -0.07128906\n",
      " -0.16503906  0.18457031 -0.08398438  0.18554688  0.11669922  0.02758789\n",
      " -0.04760742  0.17871094  0.06542969 -0.03540039  0.22949219  0.02697754\n",
      " -0.09765625  0.26953125  0.08349609 -0.13085938 -0.10107422 -0.00738525\n",
      "  0.07128906  0.14941406 -0.20605469  0.18066406 -0.15820312  0.05932617\n",
      "  0.28710938 -0.04663086  0.15136719  0.4921875  -0.27539062  0.05615234]\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of each word's vector (for this model):\", len(model[\"cat\"]))\n",
    "print(\"Sample vector for 'cat':\")\n",
    "print(model[\"cat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e4cc4c1-ad82-490d-b57b-b5eb82eec908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674139022827),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321839332581),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.5181134343147278),\n",
       " ('sultan', 0.5098593831062317),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"man\" is to \"king\" as \"woman\" is to _______\n",
    "\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcc25cb5-5543-4474-8dd5-d2a1141202ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('symbolism', 0.5135414600372314),\n",
       " ('meanings', 0.4999716579914093),\n",
       " ('resonance', 0.47358712553977966),\n",
       " ('historical_significance', 0.46956706047058105),\n",
       " ('relevance', 0.46694469451904297),\n",
       " ('importance', 0.4652005136013031),\n",
       " ('liminality', 0.45890143513679504),\n",
       " ('unknowability', 0.45856061577796936),\n",
       " ('profundity', 0.44765299558639526),\n",
       " ('significances', 0.44475480914115906)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"paltry\" is to \"significance\" as \"banal\" is to _______\n",
    "\n",
    "model.most_similar(positive=['banal', 'significance'], negative=['paltry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a869855-33e9-4cbf-94f2-4dcb928b15de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lazy_bums', 0.45563870668411255),\n",
       " ('dammit', 0.40230637788772583),\n",
       " ('bungle', 0.4007464349269867),\n",
       " ('lousy', 0.3992597460746765),\n",
       " ('dopes', 0.39685630798339844),\n",
       " ('slackers', 0.392386257648468),\n",
       " (\"f'd\", 0.3912498652935028),\n",
       " ('stinkin', 0.3887179493904114),\n",
       " ('shitty', 0.3877786695957184),\n",
       " ('gullable', 0.3874760568141937)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"clumsy\" is to \"botch\" as \"lazy\" is to ________\n",
    "\n",
    "model.most_similar(positive=['botch', 'lazy'], negative=['clumsy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab26f1b-9359-406a-8bbc-df514babf778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.9314123392105103),\n",
       " ('monarch', 0.858533501625061),\n",
       " ('princess', 0.8476566076278687),\n",
       " ('Queen_Consort', 0.8150269985198975),\n",
       " ('queens', 0.8099815249443054),\n",
       " ('crown_prince', 0.8089976906776428),\n",
       " ('royal_palace', 0.8027306795120239),\n",
       " ('monarchy', 0.8019613027572632),\n",
       " ('prince', 0.800979733467102),\n",
       " ('empress', 0.7958389520645142)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar_cosmul(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ded29e7-9e0f-46ec-95b4-c2aeabbb7f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3042949-4c05-4b77-86e4-135be01d42bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76640123"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('woman', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e968f3ed-39f3-4892-bf60-e2ad7c28dea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cats', 0.8099379539489746),\n",
       " ('dog', 0.760945737361908),\n",
       " ('kitten', 0.7464985251426697),\n",
       " ('feline', 0.7326234579086304),\n",
       " ('beagle', 0.7150582671165466),\n",
       " ('puppy', 0.7075453400611877),\n",
       " ('pup', 0.6934291124343872),\n",
       " ('pet', 0.6891531348228455),\n",
       " ('felines', 0.6755931973457336),\n",
       " ('chihuahua', 0.6709762215614319)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_word(\"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a108e3d-1b2b-492a-b7b7-f0df1a96e398",
   "metadata": {},
   "source": [
    "### Computing Average Embeddings\n",
    "\n",
    "```\n",
    "\"We first compute the average embedding distance between words that represent women—e.g., she, female—and words for occupations—e.g., teacher, lawyer.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e883072e-4e6f-4dd7-b924-197d7d18f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean of vectors among all words of each category.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "woman_words = [\"she\", \"daughter\", \"hers\", \"her\", \"mother\", \"woman\", \"girl\", \"herself\", \"female\", \"sister\", \"daughters\", \"mothers\", \"women\",\n",
    "\"girls\", \"femen\", \"sisters\", \"aunt\", \"aunts\", \"niece\", \"nieces\"]\n",
    "\n",
    "man_words = [\"he\", \"son\", \"his\", \"him\", \"father\", \"man\", \"boy\", \"himself\", \"male\", \"brother\", \"sons\", \"fathers\", \"men\", \"boys\", \"males\", \"brothers\", \"uncle\",\n",
    "\"uncles\", \"nephew\", \"nephews\"]\n",
    "\n",
    "occupations = [\"janitor\", \"statistician\", \"midwife\", \"bailiff\", \"auctioneer\", \"photographer\", \"geologist\", \"shoemaker\", \"athlete\", \"cashier\",\n",
    "\"dancer\", \"housekeeper\", \"accountant\", \"physicist\", \"gardener\", \"dentist\", \"weaver\", \"blacksmith\", \"psychologist\", \"supervisor\",\n",
    "\"mathematician\", \"surveyor\", \"tailor\", \"designer\", \"economist\", \"mechanic\", \"laborer\", \"postmaster\", \"broker\", \"chemist\", \"librarian\", \"attendant\", \"clerical\", \"musician\", \"porter\", \"scientist\", \"carpenter\", \"sailor\", \"instructor\", \"sheriff\", \"pilot\", \"inspector\", \"mason\",\n",
    "\"baker\", \"administrator\", \"architect\", \"collector\", \"operator\", \"surgeon\", \"driver\", \"painter\", \"conductor\", \"nurse\", \"cook\", \"engineer\",\n",
    "\"retired\", \"sales\", \"lawyer\", \"clergy\", \"physician\", \"farmer\", \"clerk\", \"manager\", \"guard\", \"artist\", \"smith\", \"official\", \"police\", \"doctor\",\n",
    "\"professor\", \"student\", \"judge\", \"teacher\", \"author\", \"secretary\", \"soldier\"]\n",
    "\n",
    "prof_occupations = [\"statistician\", \"auctioneer\", \"photographer\", \"geologist\", \"accountant\", \"physicist\", \"dentist\", \"psychologist\", \"supervisor\", \"mathematician\", \"designer\", \"economist\", \"postmaster\", \"broker\", \"chemist\", \"librarian\", \"scientist\", \"instructor\",\n",
    "\"pilot\", \"administrator\", \"architect\", \"surgeon\", \"nurse\", \"engineer\", \"lawyer\", \"physician\", \"manager\", \"official\", \"doctor\", \"professor\",\n",
    "\"student\", \"judge\", \"teacher\", \"author\"]\n",
    "\n",
    "average_woman_words = np.mean(np.array([model[word] for word in woman_words if word in model]), axis = 0)\n",
    "average_man_words = np.mean(np.array([model[word] for word in man_words if word in model]), axis = 0)\n",
    "average_occupations = np.mean(np.array([model[word] for word in occupations if word in model]), axis = 0)\n",
    "average_prof_occupations = np.mean(np.array([model[word] for word in prof_occupations if word in model]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6e0a72c-98b2-43a3-a064-375fc127261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(average_woman_words))\n",
    "print(len(average_man_words))\n",
    "print(len(average_occupations))\n",
    "print(len(average_prof_occupations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0d71604d-c8a8-4422-b989-98df17184082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupation distances (women, men): 0.41305923 0.44160503\n",
      "Occupation distances (women, men): 0.30585325 0.32154357\n"
     ]
    }
   ],
   "source": [
    "# Calculate distances between occations and 'man' and 'woman' words.\n",
    "def cossim(v1, v2, signed = True):\n",
    "    c = np.dot(v1, v2)/np.linalg.norm(v1)/np.linalg.norm(v2)\n",
    "    if not signed:\n",
    "        return abs(c)\n",
    "    return c\n",
    "\n",
    "def calc_distance_between_vectors(vec1, vec2, distype = ''):\n",
    "    if distype == 'norm':\n",
    "        return np.linalg.norm(np.subtract(vec1, vec2))\n",
    "    else:\n",
    "        return cossim(vec1, vec2)\n",
    "\n",
    "occupations_to_woman = calc_distance_between_vectors(average_occupations, average_woman_words)\n",
    "occupations_to_man = calc_distance_between_vectors(average_occupations, average_man_words)\n",
    "print(\"Occupation distances (women, men):\", occupations_to_woman, occupations_to_man)\n",
    "\n",
    "prof_occupations_to_woman = calc_distance_between_vectors(average_prof_occupations, average_woman_words)\n",
    "prof_occupations_to_man = calc_distance_between_vectors(average_prof_occupations, average_man_words)\n",
    "print(\"Occupation distances (women, men):\", prof_occupations_to_woman, prof_occupations_to_man)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac71d95c-e8b6-4846-9d9a-1b0b0aa47954",
   "metadata": {},
   "source": [
    "```\n",
    "\"A natural metric for the embedding bias is the average distance for women minus the average distance for men. If this value is negative, then the embedding more closely associates the occupations with men.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b2f89df-18ea-45d1-8a81-e270af4a36e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.028545797\n"
     ]
    }
   ],
   "source": [
    "embedding_bias = occupations_to_woman - occupations_to_man\n",
    "print(embedding_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aedc41d2-49f1-460f-831a-aae08f359a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Woman Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>janitor</td>\n",
       "      <td>-0.072116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>statistician</td>\n",
       "      <td>-0.058891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>midwife</td>\n",
       "      <td>0.207095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bailiff</td>\n",
       "      <td>-0.036310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>auctioneer</td>\n",
       "      <td>-0.032615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>photographer</td>\n",
       "      <td>-0.018147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>geologist</td>\n",
       "      <td>-0.083728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shoemaker</td>\n",
       "      <td>-0.093407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>athlete</td>\n",
       "      <td>-0.007814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cashier</td>\n",
       "      <td>0.082338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dancer</td>\n",
       "      <td>0.120801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>housekeeper</td>\n",
       "      <td>0.149452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>accountant</td>\n",
       "      <td>-0.011912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>physicist</td>\n",
       "      <td>-0.083374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gardener</td>\n",
       "      <td>0.025771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dentist</td>\n",
       "      <td>0.001898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>weaver</td>\n",
       "      <td>0.076620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>blacksmith</td>\n",
       "      <td>-0.138434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>0.008374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>supervisor</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mathematician</td>\n",
       "      <td>-0.105966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>surveyor</td>\n",
       "      <td>-0.080918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tailor</td>\n",
       "      <td>-0.037380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>designer</td>\n",
       "      <td>0.085329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>economist</td>\n",
       "      <td>-0.034562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mechanic</td>\n",
       "      <td>-0.148044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>laborer</td>\n",
       "      <td>-0.086100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>postmaster</td>\n",
       "      <td>0.015022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>broker</td>\n",
       "      <td>-0.034544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>chemist</td>\n",
       "      <td>-0.019658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>librarian</td>\n",
       "      <td>0.195256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>attendant</td>\n",
       "      <td>0.022081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>clerical</td>\n",
       "      <td>0.070687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>musician</td>\n",
       "      <td>-0.053546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>porter</td>\n",
       "      <td>-0.068058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>scientist</td>\n",
       "      <td>-0.024282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>carpenter</td>\n",
       "      <td>-0.149505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sailor</td>\n",
       "      <td>-0.010338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>instructor</td>\n",
       "      <td>-0.012893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>sheriff</td>\n",
       "      <td>-0.022864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>pilot</td>\n",
       "      <td>-0.024052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>inspector</td>\n",
       "      <td>-0.044788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mason</td>\n",
       "      <td>-0.153369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>baker</td>\n",
       "      <td>0.024588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>administrator</td>\n",
       "      <td>0.030143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>architect</td>\n",
       "      <td>-0.129875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>collector</td>\n",
       "      <td>-0.019949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>operator</td>\n",
       "      <td>0.016771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>surgeon</td>\n",
       "      <td>-0.040474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>driver</td>\n",
       "      <td>-0.037052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>painter</td>\n",
       "      <td>-0.022541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>conductor</td>\n",
       "      <td>-0.076276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>nurse</td>\n",
       "      <td>0.228890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>cook</td>\n",
       "      <td>0.061308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>engineer</td>\n",
       "      <td>-0.121019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>retired</td>\n",
       "      <td>-0.130752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>sales</td>\n",
       "      <td>0.039141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>lawyer</td>\n",
       "      <td>-0.048612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>clergy</td>\n",
       "      <td>0.007947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>physician</td>\n",
       "      <td>-0.021701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>farmer</td>\n",
       "      <td>-0.082799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>clerk</td>\n",
       "      <td>0.063194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>manager</td>\n",
       "      <td>-0.034745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>guard</td>\n",
       "      <td>-0.060143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>artist</td>\n",
       "      <td>0.047974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>smith</td>\n",
       "      <td>-0.060955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>official</td>\n",
       "      <td>-0.057066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>police</td>\n",
       "      <td>-0.051200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>doctor</td>\n",
       "      <td>0.004405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>professor</td>\n",
       "      <td>-0.024008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>student</td>\n",
       "      <td>0.072524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>judge</td>\n",
       "      <td>0.053706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>teacher</td>\n",
       "      <td>0.094209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>author</td>\n",
       "      <td>0.041251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>secretary</td>\n",
       "      <td>0.000454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>soldier</td>\n",
       "      <td>-0.049255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Occupation  Woman Bias\n",
       "0         janitor   -0.072116\n",
       "1    statistician   -0.058891\n",
       "2         midwife    0.207095\n",
       "3         bailiff   -0.036310\n",
       "4      auctioneer   -0.032615\n",
       "5    photographer   -0.018147\n",
       "6       geologist   -0.083728\n",
       "7       shoemaker   -0.093407\n",
       "8         athlete   -0.007814\n",
       "9         cashier    0.082338\n",
       "10         dancer    0.120801\n",
       "11    housekeeper    0.149452\n",
       "12     accountant   -0.011912\n",
       "13      physicist   -0.083374\n",
       "14       gardener    0.025771\n",
       "15        dentist    0.001898\n",
       "16         weaver    0.076620\n",
       "17     blacksmith   -0.138434\n",
       "18   psychologist    0.008374\n",
       "19     supervisor    0.003602\n",
       "20  mathematician   -0.105966\n",
       "21       surveyor   -0.080918\n",
       "22         tailor   -0.037380\n",
       "23       designer    0.085329\n",
       "24      economist   -0.034562\n",
       "25       mechanic   -0.148044\n",
       "26        laborer   -0.086100\n",
       "27     postmaster    0.015022\n",
       "28         broker   -0.034544\n",
       "29        chemist   -0.019658\n",
       "30      librarian    0.195256\n",
       "31      attendant    0.022081\n",
       "32       clerical    0.070687\n",
       "33       musician   -0.053546\n",
       "34         porter   -0.068058\n",
       "35      scientist   -0.024282\n",
       "36      carpenter   -0.149505\n",
       "37         sailor   -0.010338\n",
       "38     instructor   -0.012893\n",
       "39        sheriff   -0.022864\n",
       "40          pilot   -0.024052\n",
       "41      inspector   -0.044788\n",
       "42          mason   -0.153369\n",
       "43          baker    0.024588\n",
       "44  administrator    0.030143\n",
       "45      architect   -0.129875\n",
       "46      collector   -0.019949\n",
       "47       operator    0.016771\n",
       "48        surgeon   -0.040474\n",
       "49         driver   -0.037052\n",
       "50        painter   -0.022541\n",
       "51      conductor   -0.076276\n",
       "52          nurse    0.228890\n",
       "53           cook    0.061308\n",
       "54       engineer   -0.121019\n",
       "55        retired   -0.130752\n",
       "56          sales    0.039141\n",
       "57         lawyer   -0.048612\n",
       "58         clergy    0.007947\n",
       "59      physician   -0.021701\n",
       "60         farmer   -0.082799\n",
       "61          clerk    0.063194\n",
       "62        manager   -0.034745\n",
       "63          guard   -0.060143\n",
       "64         artist    0.047974\n",
       "65          smith   -0.060955\n",
       "66       official   -0.057066\n",
       "67         police   -0.051200\n",
       "68         doctor    0.004405\n",
       "69      professor   -0.024008\n",
       "70        student    0.072524\n",
       "71          judge    0.053706\n",
       "72        teacher    0.094209\n",
       "73         author    0.041251\n",
       "74      secretary    0.000454\n",
       "75        soldier   -0.049255"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "output = []\n",
    "\n",
    "for occupation in occupations:\n",
    "    man = calc_distance_between_vectors(model[occupation], average_man_words)\n",
    "    woman = calc_distance_between_vectors(model[occupation], average_woman_words)\n",
    "    output.append([occupation, woman - man])  \n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "display(pd.DataFrame(output, columns=[\"Occupation\", \"Woman Bias\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "428566c0-ea1b-4bd4-a5eb-1891f1503060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8498664"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctor_man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e0bd308d-80c9-4ffd-b929-81b38f44b340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40057373"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"janitor\", \"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "785f1cba-a63e-41ea-b286-979db00cd8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"genre-balanced-american-enlish_coha/1980-w.npy\", \"rb\") as f:\n",
    "    vectors = np.lib.format.read_array(f)\n",
    "\n",
    "with open(\"genre-balanced-american-enlish_coha/1980-vocab.pkl\", \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "model = KeyedVectors(vectors.shape[1])\n",
    "model.add_vectors(vocab, vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7442dfc5-0487-4bbe-a28f-35ac497e7f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0791897"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('human', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "42cffacb-0dae-4384-8814-9aaa9aa20124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3940503"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('hello', 'goodbye')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "628c68ad-c305-4530-8a7e-6fc496b8cb2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wget'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwget\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wget'"
     ]
    }
   ],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96476bf2-37ab-41b4-b92b-2178b2cc3389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
