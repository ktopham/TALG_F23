{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cd2278f-6b7f-458d-b6f5-f2cfb316520f",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "## As used in \"Word embeddings quantify 100 years of gender and ethnic stereotypes\"\n",
    "\n",
    "The article by Garg et al. investigates and validates the use of machine-learned word embeddings to study biases in language:\n",
    "\n",
    "```\n",
    "\"In word-embedding models, each word in a given language is assigned to a high-dimensional vector such that the geometry of the vectors captures semantic relations between the words — e.g., vectors being closer together has been shown to correspond to more similar words.\"\n",
    "```\n",
    "\n",
    "Using pre-trained models of large text corpora, the authors evaluate vectors of words relating to gender and ethnicity against \"neutral\" word categories to measure bias.\n",
    "\n",
    "### Load model(s) and look at vectors\n",
    "\n",
    "```\n",
    "\"For contemporary snapshot analysis, we use the standard Google News word2vec vectors trained on the Google News dataset.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818b7c0d-6062-4cd8-9680-6997f1361a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e830c9c-7c7f-414b-b7c5-66b18b0fe008",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of each word's vector (for this model):\", len(model[\"cat\"]))\n",
    "print(\"Sample vector for 'cat':\")\n",
    "print(model[\"cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17723daf-2036-4ad2-b8d0-e108e4d141bc",
   "metadata": {},
   "source": [
    "### What can you do with word vectors?\n",
    "\n",
    "The [documentation](https://radimrehurek.com/gensim/models/keyedvectors.html) (API) lists out all the associated functions and how they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4cc4c1-ad82-490d-b57b-b5eb82eec908",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.similar_by_word(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19db63f4-89f0-4df5-850e-9c608fc3d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"democracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8f5fb1-4377-4b83-b35f-04096591dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"man\" is to \"king\" as \"woman\" is to _______\n",
    "\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc25cb5-5543-4474-8dd5-d2a1141202ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"paltry\" is to \"significance\" as \"banal\" is to _______\n",
    "\n",
    "model.most_similar(positive=['banal', 'significance'], negative=['paltry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a869855-33e9-4cbf-94f2-4dcb928b15de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"clumsy\" is to \"botch\" as \"lazy\" is to ________\n",
    "\n",
    "model.most_similar(positive=['botch', 'lazy'], negative=['clumsy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded29e7-9e0f-46ec-95b4-c2aeabbb7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3042949-4c05-4b77-86e4-135be01d42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.similarity('woman', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e968f3ed-39f3-4892-bf60-e2ad7c28dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"freedom\", topn=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a108e3d-1b2b-492a-b7b7-f0df1a96e398",
   "metadata": {},
   "source": [
    "### Computing Average Embeddings\n",
    "\n",
    "```\n",
    "\"We first compute the average embedding distance between words that represent women—e.g., she, female—and words for occupations—e.g., teacher, lawyer.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e883072e-4e6f-4dd7-b924-197d7d18f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean of vectors among all words of each category.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "woman_words = [\"she\", \"daughter\", \"hers\", \"her\", \"mother\", \"woman\", \"girl\", \"herself\", \"female\", \"sister\", \"daughters\", \"mothers\", \"women\",\n",
    "\"girls\", \"femen\", \"sisters\", \"aunt\", \"aunts\", \"niece\", \"nieces\"]\n",
    "\n",
    "man_words = [\"he\", \"son\", \"his\", \"him\", \"father\", \"man\", \"boy\", \"himself\", \"male\", \"brother\", \"sons\", \"fathers\", \"men\", \"boys\", \"males\", \"brothers\", \"uncle\",\n",
    "\"uncles\", \"nephew\", \"nephews\"]\n",
    "\n",
    "occupations = [\"janitor\", \"statistician\", \"midwife\", \"bailiff\", \"auctioneer\", \"photographer\", \"geologist\", \"shoemaker\", \"athlete\", \"cashier\",\n",
    "\"dancer\", \"housekeeper\", \"accountant\", \"physicist\", \"gardener\", \"dentist\", \"weaver\", \"blacksmith\", \"psychologist\", \"supervisor\",\n",
    "\"mathematician\", \"surveyor\", \"tailor\", \"designer\", \"economist\", \"mechanic\", \"laborer\", \"postmaster\", \"broker\", \"chemist\", \"librarian\", \"attendant\", \"clerical\", \"musician\", \"porter\", \"scientist\", \"carpenter\", \"sailor\", \"instructor\", \"sheriff\", \"pilot\", \"inspector\", \"mason\",\n",
    "\"baker\", \"administrator\", \"architect\", \"collector\", \"operator\", \"surgeon\", \"driver\", \"painter\", \"conductor\", \"nurse\", \"cook\", \"engineer\",\n",
    "\"retired\", \"sales\", \"lawyer\", \"clergy\", \"physician\", \"farmer\", \"clerk\", \"manager\", \"guard\", \"artist\", \"smith\", \"official\", \"police\", \"doctor\",\n",
    "\"professor\", \"student\", \"judge\", \"teacher\", \"author\", \"secretary\", \"soldier\"]\n",
    "\n",
    "prof_occupations = [\"statistician\", \"auctioneer\", \"photographer\", \"geologist\", \"accountant\", \"physicist\", \"dentist\", \"psychologist\", \"supervisor\", \"mathematician\", \"designer\", \"economist\", \"postmaster\", \"broker\", \"chemist\", \"librarian\", \"scientist\", \"instructor\",\n",
    "\"pilot\", \"administrator\", \"architect\", \"surgeon\", \"nurse\", \"engineer\", \"lawyer\", \"physician\", \"manager\", \"official\", \"doctor\", \"professor\",\n",
    "\"student\", \"judge\", \"teacher\", \"author\"]\n",
    "\n",
    "personality_traits = ['disorganized', 'devious', 'impressionable', 'circumspect', 'impassive', 'aimless', 'effeminate', 'unfathomable', 'fickle', 'unprincipled', 'inoffensive', 'reactive', 'providential', 'resentful', 'bizarre', 'impractical', 'sarcastic', 'misguided', 'imitative', 'pedantic', 'venomous', 'erratic', 'insecure', 'resourceful', 'neurotic', 'forgiving', 'profligate', 'whimsical', 'assertive', 'incorruptible', 'individualistic', 'faithless', 'disconcerting', 'barbaric', 'hypnotic', 'vindictive', 'observant', 'dissolute', 'frightening', 'complacent', 'boisterous', 'pretentious', 'disobedient', 'tasteless', 'sedentary', 'sophisticated', 'regimental', 'mellow', 'deceitful', 'impulsive', 'playful', 'sociable', 'methodical', 'willful', 'idealistic', 'boyish', 'callous', 'pompous', 'unchanging', 'crafty', 'punctual', 'compassionate', 'intolerant', 'challenging', 'scornful', 'possessive', 'conceited', 'imprudent', 'dutiful', 'lovable', 'disloyal', 'dreamy', 'appreciative', 'forgetful', 'unrestrained', 'forceful', 'submissive', 'predatory', 'fanatical', 'illogical', 'tidy', 'aspiring', 'studious', 'adaptable', 'conciliatory', 'artful', 'thoughtless', 'deceptive', 'frugal', 'reflective', 'insulting', 'unreliable', 'stoic', 'hysterical', 'rustic', 'inhibited', 'outspoken', 'unhealthy', 'ascetic', 'skeptical', 'painstaking', 'contemplative', 'leisurely', 'sly', 'mannered', 'outrageous', 'lyrical', 'placid', 'cynical', 'irresponsible', 'vulnerable', 'arrogant', 'persuasive', 'perverse', 'steadfast', 'crisp', 'envious', 'naive', 'greedy', 'presumptuous', 'obnoxious', 'irritable', 'dishonest', 'discreet', 'sporting', 'hateful', 'ungrateful', 'frivolous', 'reactionary', 'skillful', 'cowardly', 'sordid', 'adventurous', 'dogmatic', 'intuitive', 'bland', 'indulgent', 'discontented', 'dominating', 'articulate', 'fanciful', 'discouraging', 'treacherous', 'repressed', 'moody', 'sensual', 'unfriendly', 'optimistic', 'clumsy', 'contemptible', 'focused', 'haughty', 'morbid', 'disorderly', 'considerate', 'humorous', 'preoccupied', 'airy', 'impersonal', 'cultured', 'trusting', 'respectful', 'scrupulous', 'scholarly', 'superstitious', 'tolerant', 'realistic', 'malicious', 'irrational', 'sane', 'colorless', 'masculine', 'witty', 'inert', 'prejudiced', 'fraudulent', 'blunt', 'childish', 'brittle', 'disciplined', 'responsive', 'courageous', 'bewildered', 'courteous', 'stubborn', 'aloof', 'sentimental', 'athletic', 'extravagant', 'brutal', 'manly', 'cooperative', 'unstable', 'youthful', 'timid', 'amiable', 'retiring', 'fiery', 'confidential', 'relaxed', 'imaginative', 'mystical', 'shrewd', 'conscientious', 'monstrous', 'grim', 'questioning', 'lazy', 'dynamic', 'gloomy', 'troublesome', 'abrupt', 'eloquent', 'dignified', 'hearty', 'gallant', 'benevolent', 'maternal', 'paternal', 'patriotic', 'aggressive', 'competitive', 'elegant', 'flexible', 'gracious', 'energetic', 'tough', 'contradictory', 'shy', 'careless', 'cautious', 'polished', 'sage', 'tense', 'caring', 'suspicious', 'sober', 'neat', 'transparent', 'disturbing', 'passionate', 'obedient', 'crazy', 'restrained', 'fearful', 'daring', 'prudent', 'demanding', 'impatient', 'cerebral', 'calculating', 'amusing', 'honorable', 'casual', 'sharing', 'selfish', 'ruined', 'spontaneous', 'admirable', 'conventional', 'cheerful', 'solitary', 'upright', 'stiff', 'enthusiastic', 'petty', 'dirty', 'subjective', 'heroic', 'stupid', 'modest', 'impressive', 'orderly', 'ambitious', 'protective', 'silly', 'alert', 'destructive', 'exciting', 'crude', 'ridiculous', 'subtle', 'mature', 'creative', 'coarse', 'passive', 'oppressed', 'accessible', 'charming', 'clever', 'decent', 'miserable', 'superficial', 'shallow', 'stern', 'winning', 'balanced', 'emotional', 'rigid', 'invisible', 'desperate', 'cruel', 'romantic', 'agreeable', 'hurried', 'sympathetic', 'solemn', 'systematic', 'vague', 'peaceful', 'humble', 'dull', 'expedient', 'loyal', 'decisive', 'arbitrary', 'earnest', 'confident', 'conservative', 'foolish', 'moderate', 'helpful', 'delicate', 'gentle', 'dedicated', 'hostile', 'generous', 'reliable', 'dramatic', 'precise', 'calm', 'healthy', 'attractive', 'artificial', 'progressive', 'odd', 'confused', 'rational', 'brilliant', 'intense', 'genuine', 'mistaken', 'driving', 'stable', 'objective', 'sensitive', 'neutral', 'strict', 'angry', 'profound', 'smooth', 'ignorant', 'thorough', 'logical', 'intelligent', 'extraordinary', 'experimental', 'steady', 'formal', 'faithful', 'curious', 'reserved', 'honest', 'busy', 'educated', 'liberal', 'friendly', 'efficient', 'sweet', 'surprising', 'mechanical', 'clean', 'critical', 'criminal', 'soft', 'proud', 'quiet', 'weak', 'anxious', 'solid', 'complex', 'grand', 'warm', 'slow', 'false', 'extreme', 'narrow', 'dependent', 'wise', 'organized', 'pure', 'directed', 'dry', 'obvious', 'popular', 'capable', 'secure', 'active', 'independent', 'ordinary', 'fixed', 'practical', 'serious', 'fair', 'understanding', 'constant', 'cold', 'responsible', 'deep', 'religious', 'private', 'simple', 'physical', 'original', 'working', 'strong', 'modern', 'determined', 'open', 'political', 'difficult', 'knowledge', 'kind']\n",
    "\n",
    "average_woman_words = np.mean(np.array([model[word] for word in woman_words if word in model]), axis = 0)\n",
    "average_man_words = np.mean(np.array([model[word] for word in man_words if word in model]), axis = 0)\n",
    "average_occupations = np.mean(np.array([model[word] for word in occupations if word in model]), axis = 0)\n",
    "average_prof_occupations = np.mean(np.array([model[word] for word in prof_occupations if word in model]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e0a72c-98b2-43a3-a064-375fc127261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(average_woman_words))\n",
    "print(len(average_man_words))\n",
    "print(len(average_occupations))\n",
    "print(len(average_prof_occupations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d71604d-c8a8-4422-b989-98df17184082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances between occations and 'man' and 'woman' words.\n",
    "def cossim(v1, v2, signed = True):\n",
    "    c = np.dot(v1, v2)/np.linalg.norm(v1)/np.linalg.norm(v2)\n",
    "    if not signed:\n",
    "        return abs(c)\n",
    "    return c\n",
    "\n",
    "def calc_distance_between_vectors(vec1, vec2, distype = ''):\n",
    "    if distype == 'norm':\n",
    "        return np.linalg.norm(np.subtract(vec1, vec2))\n",
    "    else:\n",
    "        return cossim(vec1, vec2)\n",
    "\n",
    "occupations_to_woman = calc_distance_between_vectors(average_occupations, average_woman_words)\n",
    "occupations_to_man = calc_distance_between_vectors(average_occupations, average_man_words)\n",
    "print(\"Occupation distances (women, men):\", occupations_to_woman, occupations_to_man)\n",
    "\n",
    "prof_occupations_to_woman = calc_distance_between_vectors(average_prof_occupations, average_woman_words)\n",
    "prof_occupations_to_man = calc_distance_between_vectors(average_prof_occupations, average_man_words)\n",
    "print(\"Occupation distances (women, men):\", prof_occupations_to_woman, prof_occupations_to_man)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac71d95c-e8b6-4846-9d9a-1b0b0aa47954",
   "metadata": {},
   "source": [
    "```\n",
    "\"A natural metric for the embedding bias is the average distance for women minus the average distance for men. If this value is negative, then the embedding more closely associates the occupations with men.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f89df-18ea-45d1-8a81-e270af4a36e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_bias = occupations_to_woman - occupations_to_man\n",
    "print(embedding_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedc41d2-49f1-460f-831a-aae08f359a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "output = []\n",
    "\n",
    "for occupation in occupations:\n",
    "    man = calc_distance_between_vectors(model[occupation], average_man_words)\n",
    "    woman = calc_distance_between_vectors(model[occupation], average_woman_words)\n",
    "    output.append([occupation, woman - man])  \n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "display(pd.DataFrame(output, columns=[\"Occupation\", \"Woman Bias\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd308d-80c9-4ffd-b929-81b38f44b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "\n",
    "for occupation in prof_occupations:\n",
    "    man = calc_distance_between_vectors(model[occupation], average_man_words)\n",
    "    woman = calc_distance_between_vectors(model[occupation], average_woman_words)\n",
    "    output.append([occupation, woman - man])  \n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "display(pd.DataFrame(output, columns=[\"Occupation\", \"Woman Bias\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef475cc7-141b-4e42-acf6-9553bbb6934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "\n",
    "for t in personality_traits:\n",
    "    man = calc_distance_between_vectors(model[t], average_man_words)\n",
    "    woman = calc_distance_between_vectors(model[t], average_woman_words)\n",
    "    output.append([t, woman - man])  \n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "display(pd.DataFrame(output, columns=[\"Trait\", \"Woman Bias\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82abe476-9cda-44a3-af8d-f41e5c1a912c",
   "metadata": {},
   "source": [
    "### Temporal Data\n",
    "\n",
    "Loading Sample COHA corpora, divided by decade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785f1cba-a63e-41ea-b286-979db00cd8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "with open(\"1950-w.npy\", \"rb\") as f:\n",
    "    vectors = np.lib.format.read_array(f)\n",
    "\n",
    "with open(\"1950-vocab.pkl\", \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "model50s = KeyedVectors(vectors.shape[1])\n",
    "model50s.add_vectors(vocab, vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7442dfc5-0487-4bbe-a28f-35ac497e7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"2000-w.npy\", \"rb\") as f:\n",
    "    vectors = np.lib.format.read_array(f)\n",
    "\n",
    "with open(\"2000-vocab.pkl\", \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "model00s = KeyedVectors(vectors.shape[1])\n",
    "model00s.add_vectors(vocab, vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e239aed-adc1-4e9a-94d1-c765443ccac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "woman_words = [\"she\", \"daughter\", \"hers\", \"her\", \"mother\", \"woman\", \"girl\", \"herself\", \"female\", \"sister\", \"daughters\", \"mothers\", \"women\",\n",
    "\"girls\", \"femen\", \"sisters\", \"aunt\", \"aunts\", \"niece\", \"nieces\"]\n",
    "\n",
    "man_words = [\"he\", \"son\", \"his\", \"him\", \"father\", \"man\", \"boy\", \"himself\", \"male\", \"brother\", \"sons\", \"fathers\", \"men\", \"boys\", \"males\", \"brothers\", \"uncle\",\n",
    "\"uncles\", \"nephew\", \"nephews\"]\n",
    "\n",
    "occupations = [\"janitor\", \"statistician\", \"midwife\", \"bailiff\", \"auctioneer\", \"photographer\", \"geologist\", \"shoemaker\", \"athlete\", \"cashier\",\n",
    "\"dancer\", \"housekeeper\", \"accountant\", \"physicist\", \"gardener\", \"dentist\", \"weaver\", \"blacksmith\", \"psychologist\", \"supervisor\",\n",
    "\"mathematician\", \"surveyor\", \"tailor\", \"designer\", \"economist\", \"mechanic\", \"laborer\", \"postmaster\", \"broker\", \"chemist\", \"librarian\", \"attendant\", \"clerical\", \"musician\", \"porter\", \"scientist\", \"carpenter\", \"sailor\", \"instructor\", \"sheriff\", \"pilot\", \"inspector\", \"mason\",\n",
    "\"baker\", \"administrator\", \"architect\", \"collector\", \"operator\", \"surgeon\", \"driver\", \"painter\", \"conductor\", \"nurse\", \"cook\", \"engineer\",\n",
    "\"retired\", \"sales\", \"lawyer\", \"clergy\", \"physician\", \"farmer\", \"clerk\", \"manager\", \"guard\", \"artist\", \"smith\", \"official\", \"police\", \"doctor\",\n",
    "\"professor\", \"student\", \"judge\", \"teacher\", \"author\", \"secretary\", \"soldier\"]\n",
    "\n",
    "prof_occupations = [\"statistician\", \"auctioneer\", \"photographer\", \"geologist\", \"accountant\", \"physicist\", \"dentist\", \"psychologist\", \"supervisor\", \"mathematician\", \"designer\", \"economist\", \"postmaster\", \"broker\", \"chemist\", \"librarian\", \"scientist\", \"instructor\",\n",
    "\"pilot\", \"administrator\", \"architect\", \"surgeon\", \"nurse\", \"engineer\", \"lawyer\", \"physician\", \"manager\", \"official\", \"doctor\", \"professor\",\n",
    "\"student\", \"judge\", \"teacher\", \"author\"]\n",
    "\n",
    "personality_traits = ['disorganized', 'devious', 'impressionable', 'circumspect', 'impassive', 'aimless', 'effeminate', 'unfathomable', 'fickle', 'unprincipled', 'inoffensive', 'reactive', 'providential', 'resentful', 'bizarre', 'impractical', 'sarcastic', 'misguided', 'imitative', 'pedantic', 'venomous', 'erratic', 'insecure', 'resourceful', 'neurotic', 'forgiving', 'profligate', 'whimsical', 'assertive', 'incorruptible', 'individualistic', 'faithless', 'disconcerting', 'barbaric', 'hypnotic', 'vindictive', 'observant', 'dissolute', 'frightening', 'complacent', 'boisterous', 'pretentious', 'disobedient', 'tasteless', 'sedentary', 'sophisticated', 'regimental', 'mellow', 'deceitful', 'impulsive', 'playful', 'sociable', 'methodical', 'willful', 'idealistic', 'boyish', 'callous', 'pompous', 'unchanging', 'crafty', 'punctual', 'compassionate', 'intolerant', 'challenging', 'scornful', 'possessive', 'conceited', 'imprudent', 'dutiful', 'lovable', 'disloyal', 'dreamy', 'appreciative', 'forgetful', 'unrestrained', 'forceful', 'submissive', 'predatory', 'fanatical', 'illogical', 'tidy', 'aspiring', 'studious', 'adaptable', 'conciliatory', 'artful', 'thoughtless', 'deceptive', 'frugal', 'reflective', 'insulting', 'unreliable', 'stoic', 'hysterical', 'rustic', 'inhibited', 'outspoken', 'unhealthy', 'ascetic', 'skeptical', 'painstaking', 'contemplative', 'leisurely', 'sly', 'mannered', 'outrageous', 'lyrical', 'placid', 'cynical', 'irresponsible', 'vulnerable', 'arrogant', 'persuasive', 'perverse', 'steadfast', 'crisp', 'envious', 'naive', 'greedy', 'presumptuous', 'obnoxious', 'irritable', 'dishonest', 'discreet', 'sporting', 'hateful', 'ungrateful', 'frivolous', 'reactionary', 'skillful', 'cowardly', 'sordid', 'adventurous', 'dogmatic', 'intuitive', 'bland', 'indulgent', 'discontented', 'dominating', 'articulate', 'fanciful', 'discouraging', 'treacherous', 'repressed', 'moody', 'sensual', 'unfriendly', 'optimistic', 'clumsy', 'contemptible', 'focused', 'haughty', 'morbid', 'disorderly', 'considerate', 'humorous', 'preoccupied', 'airy', 'impersonal', 'cultured', 'trusting', 'respectful', 'scrupulous', 'scholarly', 'superstitious', 'tolerant', 'realistic', 'malicious', 'irrational', 'sane', 'colorless', 'masculine', 'witty', 'inert', 'prejudiced', 'fraudulent', 'blunt', 'childish', 'brittle', 'disciplined', 'responsive', 'courageous', 'bewildered', 'courteous', 'stubborn', 'aloof', 'sentimental', 'athletic', 'extravagant', 'brutal', 'manly', 'cooperative', 'unstable', 'youthful', 'timid', 'amiable', 'retiring', 'fiery', 'confidential', 'relaxed', 'imaginative', 'mystical', 'shrewd', 'conscientious', 'monstrous', 'grim', 'questioning', 'lazy', 'dynamic', 'gloomy', 'troublesome', 'abrupt', 'eloquent', 'dignified', 'hearty', 'gallant', 'benevolent', 'maternal', 'paternal', 'patriotic', 'aggressive', 'competitive', 'elegant', 'flexible', 'gracious', 'energetic', 'tough', 'contradictory', 'shy', 'careless', 'cautious', 'polished', 'sage', 'tense', 'caring', 'suspicious', 'sober', 'neat', 'transparent', 'disturbing', 'passionate', 'obedient', 'crazy', 'restrained', 'fearful', 'daring', 'prudent', 'demanding', 'impatient', 'cerebral', 'calculating', 'amusing', 'honorable', 'casual', 'sharing', 'selfish', 'ruined', 'spontaneous', 'admirable', 'conventional', 'cheerful', 'solitary', 'upright', 'stiff', 'enthusiastic', 'petty', 'dirty', 'subjective', 'heroic', 'stupid', 'modest', 'impressive', 'orderly', 'ambitious', 'protective', 'silly', 'alert', 'destructive', 'exciting', 'crude', 'ridiculous', 'subtle', 'mature', 'creative', 'coarse', 'passive', 'oppressed', 'accessible', 'charming', 'clever', 'decent', 'miserable', 'superficial', 'shallow', 'stern', 'winning', 'balanced', 'emotional', 'rigid', 'invisible', 'desperate', 'cruel', 'romantic', 'agreeable', 'hurried', 'sympathetic', 'solemn', 'systematic', 'vague', 'peaceful', 'humble', 'dull', 'expedient', 'loyal', 'decisive', 'arbitrary', 'earnest', 'confident', 'conservative', 'foolish', 'moderate', 'helpful', 'delicate', 'gentle', 'dedicated', 'hostile', 'generous', 'reliable', 'dramatic', 'precise', 'calm', 'healthy', 'attractive', 'artificial', 'progressive', 'odd', 'confused', 'rational', 'brilliant', 'intense', 'genuine', 'mistaken', 'driving', 'stable', 'objective', 'sensitive', 'neutral', 'strict', 'angry', 'profound', 'smooth', 'ignorant', 'thorough', 'logical', 'intelligent', 'extraordinary', 'experimental', 'steady', 'formal', 'faithful', 'curious', 'reserved', 'honest', 'busy', 'educated', 'liberal', 'friendly', 'efficient', 'sweet', 'surprising', 'mechanical', 'clean', 'critical', 'criminal', 'soft', 'proud', 'quiet', 'weak', 'anxious', 'solid', 'complex', 'grand', 'warm', 'slow', 'false', 'extreme', 'narrow', 'dependent', 'wise', 'organized', 'pure', 'directed', 'dry', 'obvious', 'popular', 'capable', 'secure', 'active', 'independent', 'ordinary', 'fixed', 'practical', 'serious', 'fair', 'understanding', 'constant', 'cold', 'responsible', 'deep', 'religious', 'private', 'simple', 'physical', 'original', 'working', 'strong', 'modern', 'determined', 'open', 'political', 'difficult', 'knowledge', 'kind']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cffacb-0dae-4384-8814-9aaa9aa20124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate distances between occations and 'man' and 'woman' words.\n",
    "def cossim(v1, v2, signed = True):\n",
    "    c = np.dot(v1, v2)/np.linalg.norm(v1)/np.linalg.norm(v2)\n",
    "    if not signed:\n",
    "        return abs(c)\n",
    "    return c\n",
    "\n",
    "def calc_distance_between_vectors(vec1, vec2, distype = ''):\n",
    "    if distype == 'norm':\n",
    "        return np.linalg.norm(np.subtract(vec1, vec2))\n",
    "    else:\n",
    "        return cossim(vec1, vec2)\n",
    "\n",
    "models = {}\n",
    "output = []\n",
    "\n",
    "for decade, model in [(\"1950s\", model50s), (\"2000s\", model00s)]:\n",
    "    \n",
    "    average_woman_words = np.mean(np.array([model[word] for word in woman_words if word in model]), axis = 0)\n",
    "    average_man_words = np.mean(np.array([model[word] for word in man_words if word in model]), axis = 0)\n",
    "    average_occupations = np.mean(np.array([model[word] for word in occupations if word in model]), axis = 0)\n",
    "    models[decade] = [average_occupations, average_woman_words, average_man_words]\n",
    "\n",
    "available_occupations = [o for o in occupations if np.any(model50s[o]) and np.any(model00s[o])]\n",
    "\n",
    "for occupation in available_occupations:\n",
    "    row = [occupation]\n",
    "    for decade, model in [(\"1950s\", model50s), (\"2000s\", model00s)]:\n",
    "        man = calc_distance_between_vectors(model[occupation], models[decade][2]) # the average vectors for men are found at index 2.\n",
    "        woman = calc_distance_between_vectors(model[occupation], models[decade][1])\n",
    "        row.append(woman - man)  \n",
    "    output.append(row)\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "display(pd.DataFrame(output, columns=[\"Occupation\", \"Woman Bias 1950s\", \"Woman Bias 2000s\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c35e50a-b310-4f68-9139-0ddcf83327e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances between occations and 'man' and 'woman' words.\n",
    "def cossim(v1, v2, signed = True):\n",
    "    c = np.dot(v1, v2)/np.linalg.norm(v1)/np.linalg.norm(v2)\n",
    "    if not signed:\n",
    "        return abs(c)\n",
    "    return c\n",
    "\n",
    "def calc_distance_between_vectors(vec1, vec2, distype = ''):\n",
    "    if distype == 'norm':\n",
    "        return np.linalg.norm(np.subtract(vec1, vec2))\n",
    "    else:\n",
    "        return cossim(vec1, vec2)\n",
    "\n",
    "models = {}\n",
    "output = []\n",
    "\n",
    "for decade, model in [(\"1950s\", model50s), (\"2000s\", model00s)]:\n",
    "    \n",
    "    average_woman_words = np.mean(np.array([model[word] for word in woman_words if word in model]), axis = 0)\n",
    "    average_man_words = np.mean(np.array([model[word] for word in man_words if word in model]), axis = 0)\n",
    "    models[decade] = [average_woman_words, average_man_words]\n",
    "\n",
    "available_traits = [p for p in personality_traits if np.any(model50s[p]) and np.any(model00s[p])]\n",
    "\n",
    "for trait in available_traits:\n",
    "    row = [trait]\n",
    "    for decade, model in [(\"1950s\", model50s), (\"2000s\", model00s)]:\n",
    "        man = calc_distance_between_vectors(model[trait], models[decade][1]) # the average vectors for men are found at index 2.\n",
    "        woman = calc_distance_between_vectors(model[trait], models[decade][0])\n",
    "        row.append(woman - man)  \n",
    "    output.append(row)\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "display(pd.DataFrame(output, columns=[\"Trait\", \"Woman Bias 1950s\", \"Woman Bias 2000s\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c68ad-c305-4530-8a7e-6fc496b8cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test some words using either or both of the models! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc53857-17f6-4c9f-a68f-9f99c69acf58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
